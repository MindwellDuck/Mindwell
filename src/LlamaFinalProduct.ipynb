{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a574b71686f649629b0e316faaeea3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "def load_llama_model():\n",
    "    \"\"\"Load LLaMA model and tokenizer\"\"\"\n",
    "    model_name = \"/home/g4/Llama-3.2-3B-Instruct-Finetuned-combined/\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    if model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    return model, tokenizer, device\n",
    "\n",
    "model, tokenizer, device = load_llama_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = {\n",
    "    \"fortune_telling\": \"Fortune Telling/Catastrophizing\",\n",
    "    \"what_if_statements\": \"What If Statements\",\n",
    "    \"labeling\": \"Labeling/Global Labeling\",\n",
    "    \"unfair_comparisons\": \"Unfair Comparisons\",\n",
    "    \"mind_reading_conclusion\": \"Mind Reading\",\n",
    "    \"should_statements_conclusion\": \"Should Statements\",\n",
    "    \"overgeneralization\": \"Overgeneralization\",\n",
    "    \"all_or_nothing_thinking\": \"All or Nothing Thinking\",\n",
    "    \"blaming_conclusion\": \"Blaming\",\n",
    "    \"emotional_reasoning\": \"Emotional Reasoning\",\n",
    "    \"mental_filter\": \"Mental Filter\",\n",
    "    \"discounting_the_positive\": \"Discounting the Positive\",\n",
    "    \"magnification_minimization\": \"Magnification/Minimization\",\n",
    "    \"personalization_conclusion\": \"Personalization\",\n",
    "    \"jumping_to_conclusions\": \"Jumping to Conclusions\",\n",
    "    \"no_distortion\": \"No Distortion\"\n",
    "}\n",
    "\n",
    "name_to_node = {\n",
    "    \"Fortune Telling\": \"fortune_telling\",\n",
    "    \"What if?\": \"what_if_statements\",\n",
    "    \"Labeling/Global Labeling\": \"labeling\",\n",
    "    \"Unfair Comparisons\": \"unfair_comparisons\",\n",
    "    \"Mind Reading\": \"mind_reading_conclusion\",\n",
    "    \"Should Statements\": \"should_statements_conclusion\",\n",
    "    \"Overgeneralization\": \"overgeneralization\",\n",
    "    \"All or Nothing Thinking\": \"all_or_nothing_thinking\",\n",
    "    \"Blaming\": \"blaming_conclusion\",\n",
    "    \"Emotional Reasoning\": \"emotional_reasoning\",\n",
    "    \"Mental Filter\": \"mental_filter\",\n",
    "    \"Discounting the Positive\": \"discounting_the_positive\",\n",
    "    \"Magnification/Minimization\": \"magnification_minimization\",\n",
    "    \"Personalization\": \"personalization_conclusion\",\n",
    "    \"Jumping to Conclusions\": \"jumping_to_conclusions\",\n",
    "    \"No Distortion\": \"no_distortion\"\n",
    "}\n",
    "\n",
    "# Define the decision tree structure\n",
    "decision_tree = {\n",
    "    \"root\": {\n",
    "        \"question\": \"Is the thought pattern about future events or predictions?\",\n",
    "        \"yes\": \"future\",\n",
    "        \"no\": \"evidence_check\"\n",
    "    },\n",
    "    \"evidence_check\": {\n",
    "        \"question\": \"Is the thought pattern about making conclusions or assumptions?\",\n",
    "        \"yes\": \"evidence\",\n",
    "        \"no\": \"evaluation_check\"\n",
    "    },\n",
    "    \"evaluation_check\": {\n",
    "        \"question\": \"Is the thought pattern about evaluating or judging self/others/situations?\",\n",
    "        \"yes\": \"evaluation\",\n",
    "        \"no\": \"attention_check\"\n",
    "    },\n",
    "    \"attention_check\": {\n",
    "        \"question\": \"Is the thought pattern about focusing attention on specific aspects?\",\n",
    "        \"yes\": \"attention\",\n",
    "        \"no\": \"responsibility_check\"\n",
    "    },\n",
    "    \"responsibility_check\": {\n",
    "        \"question\": \"Is the thought pattern about assigning responsibility or causation?\",\n",
    "        \"yes\": \"responsibility\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"future\": {\n",
    "        \"question\": \"Are the predictions catastrophic or unbearable?\",\n",
    "        \"yes\": \"fortune_telling\",\n",
    "        \"no\": \"what_if\"\n",
    "    },\n",
    "    \"what_if\": {\n",
    "        \"question\": \"Are there repeated 'what if' questions?\",\n",
    "        \"yes\": \"what_if_statements\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"evidence\": {\n",
    "        \"question\": \"Are conclusions drawn without sufficient evidence?\",\n",
    "        \"yes\": \"jumping_to_conclusions\",\n",
    "        \"no\": \"evidence_type\"\n",
    "    },\n",
    "    \"evidence_type\": {\n",
    "        \"question\": \"Are emotions used as the primary evidence?\",\n",
    "        \"yes\": \"emotional_reasoning\",\n",
    "        \"no\": \"assumed_thoughts\"\n",
    "    },\n",
    "    \"assumed_thoughts\": {\n",
    "        \"question\": \"Are others' thoughts/intentions assumed without evidence?\",\n",
    "        \"yes\": \"mind_reading\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"evaluation\": {\n",
    "        \"question\": \"Does the evaluation involve extreme categories?\",\n",
    "        \"yes\": \"extremes\",\n",
    "        \"no\": \"standards_check\"\n",
    "    },\n",
    "    \"extremes\": {\n",
    "        \"question\": \"Does it use words like 'always', 'never', 'every time'?\",\n",
    "        \"yes\": \"overgeneralization\",\n",
    "        \"no\": \"two_options\"\n",
    "    },\n",
    "    \"two_options\": {\n",
    "        \"question\": \"Is everything sorted into only two categories?\",\n",
    "        \"yes\": \"all_or_nothing\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"standards_check\": {\n",
    "        \"question\": \"Is it about how things 'should' be?\",\n",
    "        \"yes\": \"should_statements\",\n",
    "        \"no\": \"comparison_check\"\n",
    "    },\n",
    "    \"comparison_check\": {\n",
    "        \"question\": \"Is it about comparing to others?\",\n",
    "        \"yes\": \"unfair_comparisons\",\n",
    "        \"no\": \"labels_check\"\n",
    "    },\n",
    "    \"labels_check\": {\n",
    "        \"question\": \"Is it about applying fixed, global labels?\",\n",
    "        \"yes\": \"labeling\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"attention\": {\n",
    "        \"question\": \"Is there selective focus on specific aspects?\",\n",
    "        \"yes\": \"mental_filter\",\n",
    "        \"no\": \"positive_negative_check\"\n",
    "    },\n",
    "    \"positive_negative_check\": {\n",
    "        \"question\": \"Is it about weighing positives versus negatives?\",\n",
    "        \"yes\": \"weighing_check\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"weighing_check\": {\n",
    "        \"question\": \"Is it exclusively focusing on negatives?\",\n",
    "        \"yes\": \"magnification_minimization\",\n",
    "        \"no\": \"positive_dismiss\"\n",
    "    },\n",
    "    \"positive_dismiss\": {\n",
    "        \"question\": \"Are positive experiences being dismissed?\",\n",
    "        \"yes\": \"discounting_the_positive\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    },\n",
    "    \"responsibility\": {\n",
    "        \"question\": \"Is external behavior seen as personally directed?\",\n",
    "        \"yes\": \"personalization\",\n",
    "        \"no\": \"blame_check\"\n",
    "    },\n",
    "    \"blame_check\": {\n",
    "        \"question\": \"Is there complete attribution of responsibility to self or others?\",\n",
    "        \"yes\": \"blaming\",\n",
    "        \"no\": \"no_distortion\"\n",
    "    }\n",
    "}\n",
    "\n",
    "distortion_definitions = \"\"\"All or Nothing Thinking/Polarized Thinking: I view a situation, a person or an event in “either-or” terms, fitting them into only two extreme categories instead of on a continuum.\n",
    "Fortune telling: I predict the future in negative terms and believe that what will happen will be so awful that I will not be able to stand it.\n",
    "Emotional reasoning:  I believe my emotions reflect reality and let them guide my attitudes and judgments.\n",
    "Labeling/Global Labeling: I put a fixed, global label, usually negative, on myself or others.\n",
    "Mental Filter: I pay attention to one or a few details and fail to see the whole picture.\n",
    "Mind reading: I believe that I know the thoughts or intentions of others (or that they know my thoughts or intentions) without having sufficient evidence\n",
    "Overgeneralization: I take isolated negative cases and generalize them, transforming them in a never-ending pattern, by repeatedly using words such as “always”, “never”, “ever”, “whole”, “entire”, etc\n",
    "Personalization: I assume that others’ behaviors and external events concern (or are directed to) myself without considering other plausible explanations.\n",
    "Should statements (also “musts”, “oughts”, “have tos”): I tell myself that events, people’s behaviors, and my own attitudes “should” be the way I expected them to be and not as they really are.\n",
    "Blaming (others or oneself): I direct my attention to others as sources of my negative feelings and experiences, failing to consider my own responsibility; or, conversely, I take responsibility for others’ behaviors and attitudes.\n",
    "What if?: I keep asking myself questions such as “what if something happens?”\n",
    "Discounting the positive: I disqualify positive experiences or events insisting that they do not count.\n",
    "Magnification/minimization: I evaluate myself, others, and situations placing greater importance on the negatives and/or placing much less importance on the positives.\n",
    "Jumping to conclusions: I draw conclusions (negative or positive) from little or no confirmatory evidence.\n",
    "Unfair comparisons: I compare myself with others who seem to do better than I do and place myself in a disadvantageous position.\n",
    "\"\"\"\n",
    "system_message = \"\"\"You are a helpful assistant that can only respond with \"Yes\" or \"No\". Follow these rules:\n",
    "1. You must answer with exactly \"Yes\" or \"No\" (case-sensitive)\n",
    "2. Do not add any other words or punctuation\n",
    "3. If you are not completely certain, answer \"No\"\n",
    "4. These are the only two valid responses: \"Yes\" or \"No\\\"\"\"\"\n",
    "\n",
    "def is_leaf_node(node_id: str) -> bool:\n",
    "    \"\"\"Check if a node is a leaf node (final distortion).\"\"\"\n",
    "    return isinstance(decision_tree[node_id], str)\n",
    "\n",
    "def get_distortion_description(distortion: str) -> str:\n",
    "    \"\"\"Get the description of a specific distortion.\"\"\"\n",
    "    return distortions.get(distortion, \"Unknown distortion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(text: str, count) -> str:\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message,\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    " ]\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=True, return_dict=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=count,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ef5ac92b1545f2b6d90904d9b457d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28mprint\u001b[39m(node, o1, o2)\n\u001b[1;32m     44\u001b[0m             err \u001b[38;5;241m=\u001b[39m err \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mtotal\u001b[49m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(err, total)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "translate = {\n",
    "    'All-or-nothing thinking' : 'all_or_nothing_thinking',\n",
    "    'Emotional Reasoning': 'emotional_reasoning',\n",
    "    'Fortune-telling': 'fortune_telling',\n",
    "    'Labeling': 'labeling',\n",
    "    'Magnification': 'magnification_minimization',\n",
    "    'Mental filter': 'mental_filter',\n",
    "    'Mind Reading': 'mind_reading_conclusion',\n",
    "    'Overgeneralization': 'overgeneralization',\n",
    "    \"No Distortion\": \"\",\n",
    "    \"Personalization\": 'personalization_conclusion',\n",
    "    \"Should statements\": \"should_statements_conclusion\",\n",
    "    \"Emotional Reasoning\": \"emotional_reasoning\",\n",
    "    \"\": ''\n",
    "}\n",
    "\n",
    "def make_question(text: str, question: str):\n",
    "    return f'Given the following text:\\n\\n{text}\\n\\n Answer the question: {question}\\n\\n'\n",
    "\n",
    "total = 0\n",
    "err = 0\n",
    "with open('/home/g4/Downloads/Annotated_data - Annotated_data.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    header = next(csv_reader)\n",
    "    for row in tqdm(csv_reader):\n",
    "        text=row[1]\n",
    "        o1=translate[row[3]]\n",
    "        o2=translate[row[4]]\n",
    "        # print(text)\n",
    "        node = 'root'\n",
    "        while node in decision_tree:\n",
    "            current = decision_tree[node]\n",
    "            response = generate_response(make_question(text, current['question']), 1)\n",
    "            # print(current['question'], response)\n",
    "            if \"yes\" in response.lower():\n",
    "                node = current['yes']\n",
    "            else:\n",
    "                node = current['no']\n",
    "\n",
    "        if node in translate.values():\n",
    "            total = total + 1\n",
    "            if node != o1 and node != o2:\n",
    "                print(node, o1, o2)\n",
    "                err = err + 1\n",
    "            print(float(err)/total)\n",
    "\n",
    "    print(err, total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
