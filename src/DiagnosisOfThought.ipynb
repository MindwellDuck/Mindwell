{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipCUMoSg6Xdu",
        "outputId": "818762ce-69d7-4f41-d3d3-0aea36a9dbaa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')\n",
        "folder_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics\"\n",
        "\n",
        "all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for file_path in all_files:\n",
        "\n",
        "    df_temp = pd.read_csv(file_path)\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    df_temp[\"source_file\"] = file_name\n",
        "\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df_combined = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data.csv\"\n",
        "\n",
        "df_combined.to_csv(output_path, index=False)\n",
        "print(f\"Combined data saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOHKpxfj-8w2",
        "outputId": "e28abfd2-f51e-4157-e3dc-702b0e67cfee"
      },
      "outputs": [],
      "source": [
        "print(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHurzSYkclSQ",
        "outputId": "7f8c317a-45a1-4847-94da-bc16907b8042"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Provide the full path to all_data.csv in Google Drive\n",
        "csv_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter rows by text length in the 4th column\n",
        "df_filtered = df[(df.iloc[:, 4] > 10) & (df.iloc[:, 4] <= 250)]\n",
        "\n",
        "# Save output\n",
        "output_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data_filtered.csv\"\n",
        "df_filtered.to_csv(output_path, index=False)\n",
        "print(f\"Filtered data saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHXcjzaelK7G",
        "outputId": "92506a45-c59e-4ddd-ba12-9ce76c88dc70"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# 1. Read the filtered data\n",
        "input_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data_filtered.csv\"\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "# 2. Shuffle the rows\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 3. Split into multiple CSV files, each with up to 200 rows\n",
        "max_rows = 200\n",
        "total_rows = len(df_shuffled)\n",
        "\n",
        "# Calculate how many chunks are needed\n",
        "num_chunks = math.ceil(total_rows / max_rows)\n",
        "\n",
        "for i in range(num_chunks):\n",
        "    # Start and end index for the chunk\n",
        "    start_index = i * max_rows\n",
        "    end_index = min(start_index + max_rows, total_rows)\n",
        "\n",
        "    # Slice the DataFrame\n",
        "    chunk = df_shuffled.iloc[start_index:end_index]\n",
        "\n",
        "    # Name the output file (e.g., part_1, part_2, ...)\n",
        "    output_path = f\"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data_part_{i+1}.csv\"\n",
        "    chunk.to_csv(output_path, index=False)\n",
        "    print(f\"Saved {output_path} with {len(chunk)} rows.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRW1qq8_5qAy",
        "outputId": "050e3523-26ef-485f-e667-7f9e11c806ad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data_part_1.csv\"\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "# Define your prompts\n",
        "prompt1 = \"\"\"\n",
        "Given a text, our task is to 1) finish a few diagnose of thought questions to analyze the thought patterns of a person. Then based on the diagnose of thought analysis, 2) identify if there is cognitive distortion in the speech; 3) Recognizing the specific types of the cognitive distortion. Here we consider the following common distortions:\n",
        "\n",
        "All or Nothing Thinking/Polarized Thinking: I view a situation, a person or an event in “either-or” terms, fitting them into only two extreme categories instead of on a continuum.\n",
        "Fortune telling (also called catastrophizing): I predict the future in negative terms and believe that what will happen will be so awful that I will not be able to stand it.\n",
        "Emotional reasoning:  I believe my emotions reflect reality and let them guide my attitudes and judgments.\n",
        "Labeling/Global Labeling: I put a fixed, global label, usually negative, on myself or others.\n",
        "Mental Filter(): I pay attention to one or a few details and fail to see the whole picture.\n",
        "Mind reading: I believe that I know the thoughts or intentions of others (or that they know my thoughts or intentions) without having sufficient evidence\n",
        "Overgeneralization: I take isolated negative cases and generalize them, transforming them in a never-ending pattern, by repeatedly using words such as “always”, “never”, “ever”, “whole”, “entire”, etc\n",
        "Personalization: I assume that others’ behaviors and external events concern (or are directed to) myself without considering other plausible explanations.\n",
        "Should statements (also “musts”, “oughts”, “have tos”): I tell myself that events, people’s behaviors, and my own attitudes “should” be the way I expected them to be and not as they really are.\n",
        "Blaming (others or oneself): I direct my attention to others as sources of my negative feelings and experiences, failing to consider my own responsibility; or, conversely, I take responsibility for others’ behaviors and attitudes.\n",
        "What if?: I keep asking myself questions such as “what if something happens?”\n",
        "Discounting the positive: I disqualify positive experiences or events insisting that they do not count.\n",
        "Magnification/minimization: I evaluate myself, others, and situations placing greater importance on the negatives and/or placing much less importance on the positives.\n",
        "Jumping to conclusions (also called arbitrary inference): I draw conclusions (negative or positive) from little or no confirmatory evidence.\n",
        "Unfair comparisons: I compare myself with others who seem to do better than I do and place myself in a disadvantageous position.\n",
        "\"\"\"\n",
        "\n",
        "prompt2 = \"\"\"\n",
        "Based on this person's text, finish the following diagnosis of thought questions: 1. what is the situation? Find out the facts that are objective; what is this person thinking or imagining? Find out the thoughts or opinions that are subjective. 2. what makes this person think the thought is true or is not true? Find out the reasoning processes that support and do not support these thoughts. 3. why does this person come up with such reasoning process supporting the thought? What’s the underlying cognition mode of it?\n",
        "\"\"\"\n",
        "\n",
        "prompt3 = \"\"\"\n",
        "Please first answer: if there is cognitive distortion in the speech; Answer ’yes’ or ’no’; Please then answer: Recognizing the specific types of the cognitive distortion in the speech. There may be one type of cognitive distortion or multiple types involved. If there are multiple types, please give the top 2 dominant ones. Please only give the distortion type names separated by comma.\n",
        "\"\"\"\n",
        "\n",
        "# Function to send text to DeepSeek and get responses\n",
        "def analyze_text_with_deepseek(text):\n",
        "    # Replace with your DeepSeek API endpoint and API key\n",
        "    api_url = \"https://api.deepseek.com/v1/analyze\"\n",
        "    headers = {\n",
        "        \"Authorization\": \"\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Combine prompts with the text\n",
        "    full_prompt = f\"{prompt1}\\n\\n{text}\\n\\n{prompt2}\\n\\n{prompt3}\"\n",
        "\n",
        "    # Send request to DeepSeek\n",
        "    response = requests.post(api_url, headers=headers, json={\"prompt\": full_prompt})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()  # Assuming DeepSeek returns a JSON response\n",
        "    else:\n",
        "        return {\"error\": f\"API request failed with status code {response.status_code}\"}\n",
        "\n",
        "# Apply the function to each row in the CSV\n",
        "df['Analysis'] = df.iloc[:, 3].apply(analyze_text_with_deepseek)\n",
        "\n",
        "# Save the results to a new CSV file\n",
        "df.to_csv('analyzed_data.csv', index=False)\n",
        "\n",
        "print(\"Analysis complete. Results saved to 'analyzed_data.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhQjy98572gU",
        "outputId": "c78fa64b-b9e9-401b-8669-7115ffff9bfc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client with DeepSeek's API\n",
        "client = OpenAI(api_key=\"\", base_url=\"https://openrouter.ai/api/v1\")\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/Reddit_Data_Collection_statistics/all_data_part_2.csv\"\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "# Define your prompts\n",
        "prompt1 = \"\"\"\n",
        "Given a text, our task is to 1) finish a few diagnose of thought questions to analyze the thought patterns of a person. Then based on the diagnose of thought analysis, 2) identify if there is cognitive distortion in the speech; 3) Recognizing the specific types of the cognitive distortion. Here we consider the following common distortions:\n",
        "\n",
        "All or Nothing Thinking/Polarized Thinking: I view a situation, a person or an event in “either-or” terms, fitting them into only two extreme categories instead of on a continuum.\n",
        "Fortune telling (also called catastrophizing): I predict the future in negative terms and believe that what will happen will be so awful that I will not be able to stand it.\n",
        "Emotional reasoning:  I believe my emotions reflect reality and let them guide my attitudes and judgments.\n",
        "Labeling/Global Labeling: I put a fixed, global label, usually negative, on myself or others.\n",
        "Mental Filter(): I pay attention to one or a few details and fail to see the whole picture.\n",
        "Mind reading: I believe that I know the thoughts or intentions of others (or that they know my thoughts or intentions) without having sufficient evidence\n",
        "Overgeneralization: I take isolated negative cases and generalize them, transforming them in a never-ending pattern, by repeatedly using words such as “always”, “never”, “ever”, “whole”, “entire”, etc\n",
        "Personalization: I assume that others’ behaviors and external events concern (or are directed to) myself without considering other plausible explanations.\n",
        "Should statements (also “musts”, “oughts”, “have tos”): I tell myself that events, people’s behaviors, and my own attitudes “should” be the way I expected them to be and not as they really are.\n",
        "Blaming (others or oneself): I direct my attention to others as sources of my negative feelings and experiences, failing to consider my own responsibility; or, conversely, I take responsibility for others’ behaviors and attitudes.\n",
        "What if?: I keep asking myself questions such as “what if something happens?”\n",
        "Discounting the positive: I disqualify positive experiences or events insisting that they do not count.\n",
        "Magnification/minimization: I evaluate myself, others, and situations placing greater importance on the negatives and/or placing much less importance on the positives.\n",
        "Jumping to conclusions (also called arbitrary inference): I draw conclusions (negative or positive) from little or no confirmatory evidence.\n",
        "Unfair comparisons: I compare myself with others who seem to do better than I do and place myself in a disadvantageous position.\n",
        "\"\"\"\n",
        "\n",
        "prompt2 = \"\"\"\n",
        "Based on this person's text, finish the following diagnosis of thought questions: 1. what is the situation? Find out the facts that are objective; what is this person thinking or imagining? Find out the thoughts or opinions that are subjective. 2. what makes this person think the thought is true or is not true? Find out the reasoning processes that support and do not support these thoughts. 3. why does this person come up with such reasoning process supporting the thought? What’s the underlying cognition mode of it?\n",
        "\"\"\"\n",
        "\n",
        "prompt3 = \"\"\"\n",
        "Please first answer: if there is cognitive distortion in the speech; Answer ’yes’ or ’no’; Please then answer: Recognizing the specific types of the cognitive distortion in the speech. There may be one type of cognitive distortion or multiple types involved. If there are multiple types, please give the top 2 dominant ones. Please only give the distortion type names separated by comma.\n",
        "\"\"\"\n",
        "\n",
        "# Function to send text to DeepSeek and get responses\n",
        "def analyze_text_with_deepseek(text):\n",
        "    # Combine prompts with the text\n",
        "    full_prompt = f\"{prompt1}\\n\\n{text}\\n\\n{prompt2}\\n\\n{prompt3}\"\n",
        "\n",
        "    # Send request to DeepSeek\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek/deepseek-r1\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": full_prompt},\n",
        "        ],\n",
        "        stream=False\n",
        "    )\n",
        "\n",
        "    # Extract the response content\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Apply the function to the fourth column (index 3) in each row\n",
        "df['Analysis'] = df.iloc[:, 3].apply(analyze_text_with_deepseek)\n",
        "\n",
        "# Save the results to a new CSV file\n",
        "df.to_csv('analyzed_data.csv', index=False)\n",
        "\n",
        "print(\"Analysis complete. Results saved to 'analyzed_data.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1/7 [01:41<10:06, 101.14s/it]\n",
            "  0%|          | 0/12 [01:41<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     39\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf I can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get a good mark, then I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm talentless.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy excitement will not allow me to perform on stage.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is you who made me feel bad.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m ]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m tqdm(examples):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(analyze_text_with_ollama(example)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</think>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
            "Cell \u001b[0;32mIn[1], line 35\u001b[0m, in \u001b[0;36manalyze_text_with_ollama\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(prompts):\n\u001b[1;32m     34\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt})\n\u001b[0;32m---> 35\u001b[0m     response \u001b[38;5;241m=\u001b[39m ollama\u001b[38;5;241m.\u001b[39mchat(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-r1:14b\u001b[39m\u001b[38;5;124m\"\u001b[39m, messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m     36\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ollama/_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    334\u001b[0m     ChatResponse,\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    337\u001b[0m     json\u001b[38;5;241m=\u001b[39mChatRequest(\n\u001b[1;32m    338\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    339\u001b[0m       messages\u001b[38;5;241m=\u001b[39m[message \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m _copy_messages(messages)],\n\u001b[1;32m    340\u001b[0m       tools\u001b[38;5;241m=\u001b[39m[tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m _copy_tools(tools)],\n\u001b[1;32m    341\u001b[0m       stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    342\u001b[0m       \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m    343\u001b[0m       options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    344\u001b[0m       keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m    345\u001b[0m     )\u001b[38;5;241m.\u001b[39mmodel_dump(exclude_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    346\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    347\u001b[0m   )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ollama/_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_raw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mjson())\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/ollama/_client.py:118\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    119\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import ollama\n",
        "from tqdm import tqdm\n",
        "\n",
        "prompts = [\"\"\"Understand the following definitions:\n",
        "    All or Nothing Thinking/Polarized Thinking: I view a situation, a person or an event in “either-or” terms, fitting them into only two extreme categories instead of on a continuum.\n",
        "    Fortune telling (also called catastrophizing): I predict the future in negative terms and believe that what will happen will be so awful that I will not be able to stand it.\n",
        "    Emotional reasoning:  I believe my emotions reflect reality and let them guide my attitudes and judgments.\n",
        "    Labeling/Global Labeling: I put a fixed, global label, usually negative, on myself or others.\n",
        "    Mental Filter(): I pay attention to one or a few details and fail to see the whole picture.\n",
        "    Mind reading: I believe that I know the thoughts or intentions of others (or that they know my thoughts or intentions) without having sufficient evidence\n",
        "    Overgeneralization: I take isolated negative cases and generalize them, transforming them in a never-ending pattern, by repeatedly using words such as “always”, “never”, “ever”, “whole”, “entire”, etc\n",
        "    Personalization: I assume that others’ behaviors and external events concern (or are directed to) myself without considering other plausible explanations.\n",
        "    Should statements (also “musts”, “oughts”, “have tos”): I tell myself that events, people’s behaviors, and my own attitudes “should” be the way I expected them to be and not as they really are.\n",
        "    Blaming (others or oneself): I direct my attention to others as sources of my negative feelings and experiences, failing to consider my own responsibility; or, conversely, I take responsibility for others’ behaviors and attitudes.\n",
        "    What if?: I keep asking myself questions such as “what if something happens?”\n",
        "    Discounting the positive: I disqualify positive experiences or events insisting that they do not count.\n",
        "    Magnification/minimization: I evaluate myself, others, and situations placing greater importance on the negatives and/or placing much less importance on the positives.\n",
        "    Jumping to conclusions (also called arbitrary inference): I draw conclusions (negative or positive) from little or no confirmatory evidence.\n",
        "    Unfair comparisons: I compare myself with others who seem to do better than I do and place myself in a disadvantageous position.\"\"\",\n",
        "\"\", # left empty for the text to be analyzed.\n",
        "\"What is this person thinking or imagining?\",\n",
        "\"Which thoughts or opinions are subjective and which are objective?\",\n",
        "\"What makes this person think the thought his thought is true?\",\n",
        "\"Is there cognitive distortion in the speech?\",\n",
        "\"What cognitive distortions are present in the speech? Please answer with a maximum of two cognitive distortions.\",\n",
        "]\n",
        "\n",
        "def analyze_text_with_ollama(text):\n",
        "    prompts[1] = \"Given the following text, answer the questions in my following messages.\\n\\n\" + text\n",
        "    messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a therpaist specializing in cognitive behavioural therapy.\"},\n",
        "    ]\n",
        "    for prompt in tqdm(prompts):\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        response = ollama.chat(model=\"deepseek-r1:14b\", messages=messages)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": response['message']['content']})\n",
        "    return response['message']['content']\n",
        "\n",
        "examples = [\n",
        "    \"If I can't get a good mark, then I'm talentless.\",\n",
        "    \"My excitement will not allow me to perform on stage.\",\n",
        "    \"My luck still allows me to hold this position.\",\n",
        "    \"I feel that the event will be boring.\",\n",
        "    \"My friend is short-sighted.\",\n",
        "    \"My mistake at the meeting suggests that I do not know how to behave in society.\",\n",
        "    \"Bonus does not mean that I do a good job.\",\n",
        "    \"Despite the fact that I fulfilled the plan, my mistake in the report indicates that I am stupid.\",\n",
        "    \"He or she thinks I'm not attractive / handsome.\",\n",
        "    \"She / he talks to me rudely because I cannot explain my request.\",\n",
        "    \"I have to get married before twenty-five because that's the way it is.\",\n",
        "    \"It is you who made me feel bad.\",\n",
        "]\n",
        "\n",
        "for example in tqdm(examples):\n",
        "    print(analyze_text_with_ollama(example).split(\"</think>\\n\\n\", 1)[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
